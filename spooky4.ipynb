{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "\n",
    "#%matplotlib notebook\n",
    "\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 2) (8392, 1) (8392, 3)\n",
      "{'author'}\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "\n",
    "# use this if in fmi-hw... repo\n",
    "# train = pd.read_csv(\"data/spooky/train.zip\", index_col=['id'])\n",
    "# test = pd.read_csv(\"data/spooky/test.zip\", index_col=['id'])\n",
    "# sample_submission = pd.read_csv(\"data/spooky/sample_submission.zip\", index_col=['id'])\n",
    "\n",
    "train = pd.read_csv(\"data/train.zip\", index_col=['id'])\n",
    "test = pd.read_csv(\"data/test.zip\", index_col=['id'])\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.zip\", index_col=['id'])\n",
    "\n",
    "\n",
    "print(train.shape, test.shape, sample_submission.shape)\n",
    "print(set(train.columns) - set(test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ~~Първо - baseline модел~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>thi process, however, afford me no mean of asc...</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never onc occur to me that the fumbl might ...</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In hi left hand wa a gold snuff box, from whic...</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>how love is spring As we look from windsor ter...</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>find noth else, not even gold, the superintend...</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   stemmed  \\\n",
       "id                                                           \n",
       "id26305  thi process, however, afford me no mean of asc...   \n",
       "id17569  It never onc occur to me that the fumbl might ...   \n",
       "id11008  In hi left hand wa a gold snuff box, from whic...   \n",
       "id27763  how love is spring As we look from windsor ter...   \n",
       "id12958  find noth else, not even gold, the superintend...   \n",
       "\n",
       "                                                      text  \n",
       "id                                                          \n",
       "id26305  This process, however, afforded me no means of...  \n",
       "id17569  It never once occurred to me that the fumbling...  \n",
       "id11008  In his left hand was a gold snuff box, from wh...  \n",
       "id27763  How lovely is spring As we looked from Windsor...  \n",
       "id12958  Finding nothing else, not even gold, the Super...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore = train.copy()\n",
    "stem = PorterStemmer()\n",
    "explore['stemmed'] = explore.text.apply(lambda t: \" \".join([stem.stem(w) for w in t.split()])) \n",
    "explore[['stemmed', 'text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ~~Допълнителните фичъри не сработиха, стеминга също.~~\n",
    "\n",
    "Остават да пробвам:\n",
    "\n",
    "* ~~Оптимизиране на модела с CountVectorizer.~~\n",
    "* Добавяне на още фичъри, от латентни пространства (LDA) - topic modeling.\n",
    "* Word embeddings с невронни мрежи.\n",
    "* Стакинг на класификатори.\n",
    "\n",
    "За сега ще разгледаме само оптимизирането на модела."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import sklearn_api\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "documents = train.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire processing of the texts has to be automated via pipeline interface - tokenization, create dict, doc2bow/text2bow, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'length': len(text),\n",
    "                 'num_sentences': text.count('.')}\n",
    "                for text in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "              \n",
    "            # Pipeline for gensim LDA\n",
    "            ('gensim', Pipeline([\n",
    "                ('bows', sklearn_api.text2bow.Text2BowTransformer()),\n",
    "                ('tfidf', sklearn_api.tfidf.TfIdfTransformer()),\n",
    "                ('lda', sklearn_api.ldamodel.LdaTransformer()),\n",
    "#                 ('selector', ItemSelector(key='subject')),\n",
    "#                 ('tfidf', TfidfVectorizer(min_df=50)),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for standard bag-of-words model for body\n",
    "            ('scikit', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "#                 ('best', TruncatedSVD(n_components=50)),\n",
    "            ])),\n",
    "\n",
    "#             # Pipeline for pulling ad hoc features from stats\n",
    "#             ('text_stats', Pipeline([\n",
    "#                 ('stats', TextStats()),  # returns a list of dicts\n",
    "#                 ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "#             ])),\n",
    "\n",
    "        ],\n",
    "\n",
    "#         # weight components in FeatureUnion\n",
    "#         transformer_weights={\n",
    "#             'gensim': 0.8,\n",
    "#             'scikit': 0.5,\n",
    "#             'text_stats': 1.0,\n",
    "#         },\n",
    "    )),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Office | Home |\n",
    "|:------------- |:------------- |\n",
    "| [ 0.59803922  0.59653693  0.59509579] | [ 0.58838848  0.58565737  0.58850575] |\n",
    "| CPU times: user 329 ms, sys: 1.26 s, total: 1.59 s | CPU times: user 367 ms, sys: 608 ms, total: 975 ms |\n",
    "| Wall time: 2min 40s | Wall time: 3min 22s |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "            \n",
    "            # Pipeline for gensim LDA\n",
    "            ('gensim', Pipeline([\n",
    "                ('bows', sklearn_api.text2bow.Text2BowTransformer()),\n",
    "                ('tfidf', sklearn_api.tfidf.TfIdfTransformer()),\n",
    "                ('lda', sklearn_api.ldamodel.LdaTransformer()),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for standard bag-of-words model for body\n",
    "            ('scikit', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "#                 ('best', TruncatedSVD(n_components=50)),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for pulling ad hoc features from stats\n",
    "            ('text_stats', Pipeline([\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "\n",
    "        ],\n",
    "\n",
    "#         # weight components in FeatureUnion\n",
    "#         transformer_weights={\n",
    "#             'gensim': 0.8,\n",
    "#             'scikit': 0.5,\n",
    "#             'text_stats': 1.0,\n",
    "#         },\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Home |\n",
    "| ----- |\n",
    "| [ 0.72840074  0.72019614  0.73042146] |\n",
    "| CPU times: user 328 ms, sys: 120 ms, total: 448 ms |\n",
    "| Wall time: 3min 13s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Try weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_count_word = {\"tfidf__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "                      \"tfidf__analyzer\": ['word'],\n",
    "                      \"tfidf__max_df\":[1.0, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "                      \"tfidf__min_df\":[2, 3, 5, 10],\n",
    "                      \"tfidf__lowercase\": [False, True],\n",
    "                      \"tfidf__stop_words\": [None, stopwords]}\n",
    "\n",
    "params_count_char = {\"features__ngram_range\": [(1,4), (1,5), (1,6)],\n",
    "                      \"features__analyzer\": ['char'],\n",
    "                      \"features__max_df\":[1.0, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "                      \"features__min_df\":[2, 3, 5, 10],\n",
    "                      \"features__lowercase\": [False, True],\n",
    "                      \"features__stop_words\": [None, stopwords]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check if we can pass params OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search():\n",
    "#     params = {\n",
    "#         \"clf__C\": [0.01, 0.1, 0.3, 1, 3, 10],\n",
    "#         \"clf__class_weight\": [None, 'balanced']\n",
    "#     }\n",
    "\n",
    "    params = {\n",
    "        \"clf__alpha\": [0.001, 0.005, 0.01, 0.05, 0.1, 0.3]\n",
    "    }\n",
    "\n",
    "    params.update(params_count_word)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for gensim LDA\n",
    "                ('gensim', Pipeline([\n",
    "                    ('bows', sklearn_api.text2bow.Text2BowTransformer()),\n",
    "                    ('apitfidf', sklearn_api.tfidf.TfIdfTransformer()),\n",
    "                    ('lda', sklearn_api.ldamodel.LdaTransformer()),\n",
    "                ])),\n",
    "\n",
    "                # Pipeline for standard bag-of-words model for body\n",
    "                ('scikit', Pipeline([\n",
    "                    ('tfidf', TfidfVectorizer()),\n",
    "    #                 ('best', TruncatedSVD(n_components=50)),\n",
    "                ])),\n",
    "\n",
    "                # Pipeline for pulling ad hoc features from stats\n",
    "                ('text_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            transformer_weights={\n",
    "                'gensim': 0.8,\n",
    "                'scikit': 0.5,\n",
    "                'text_stats': 1.0,\n",
    "            },\n",
    "        )),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=params, \n",
    "                                       scoring='neg_log_loss',\n",
    "#                                        n_iter=20, cv=3, n_jobs=2)\n",
    "                                       n_iter=20, cv=3, n_jobs=2)\n",
    "\n",
    "    random_search.fit(train.text, train.author)\n",
    "    report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/bob/.local/lib/python3.6/site-packages/gensim/models/ldamodel.py:802: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.407 (std: 0.002)\n",
      "Parameters: {'clf__alpha': 0.1}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.408 (std: 0.003)\n",
      "Parameters: {'clf__alpha': 0.05}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.449 (std: 0.000)\n",
      "Parameters: {'clf__alpha': 0.3}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.453 (std: 0.005)\n",
      "Parameters: {'clf__alpha': 0.01}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.486 (std: 0.007)\n",
      "Parameters: {'clf__alpha': 0.005}\n",
      "\n",
      "CPU times: user 2min 49s, sys: 4.18 s, total: 2min 53s\n",
      "Wall time: 27min 9s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# random_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with rank: 1\n",
    "Mean validation score: -0.407 (std: 0.002)\n",
    "Parameters: {'clf__alpha': 0.1}\n",
    "\n",
    "Model with rank: 2\n",
    "Mean validation score: -0.408 (std: 0.003)\n",
    "Parameters: {'clf__alpha': 0.05}\n",
    "\n",
    "Model with rank: 3\n",
    "Mean validation score: -0.449 (std: 0.000)\n",
    "Parameters: {'clf__alpha': 0.3}\n",
    "\n",
    "Model with rank: 4\n",
    "Mean validation score: -0.453 (std: 0.005)\n",
    "Parameters: {'clf__alpha': 0.01}\n",
    "\n",
    "Model with rank: 5\n",
    "Mean validation score: -0.486 (std: 0.007)\n",
    "Parameters: {'clf__alpha': 0.005}\n",
    "\n",
    "CPU times: user 2min 49s, sys: 4.18 s, total: 2min 53s\n",
    "Wall time: 27min 9s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add tfidf params. Disable the union weights?\n",
    "Also, do I have a book - n_iter=6 took almost 1/2 hour, so I expect the n_iter=20 to be about x4. Oh, make that another x10 because of trying with n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search():\n",
    "#     params = {\n",
    "#         \"clf__C\": [0.01, 0.1, 0.3, 1, 3, 10],\n",
    "#         \"clf__class_weight\": [None, 'balanced']\n",
    "#     }\n",
    "\n",
    "    params = {\n",
    "        \"clf__alpha\": [0.03, 0.1, 0.3]\n",
    "    }\n",
    "\n",
    "    params.update(params_count_word)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for gensim LDA\n",
    "                ('gensim', Pipeline([\n",
    "                    ('bows', sklearn_api.text2bow.Text2BowTransformer()),\n",
    "                    ('apitfidf', sklearn_api.tfidf.TfIdfTransformer()),\n",
    "                    ('lda', sklearn_api.ldamodel.LdaTransformer()),\n",
    "                ])),\n",
    "\n",
    "                # Pipeline for standard bag-of-words model for body\n",
    "                ('scikit', Pipeline([\n",
    "                    ('tfidf', TfidfVectorizer()),\n",
    "    #                 ('best', TruncatedSVD(n_components=50)),\n",
    "                ])),\n",
    "\n",
    "                # Pipeline for pulling ad hoc features from stats\n",
    "                ('text_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            transformer_weights={\n",
    "                'gensim': 0.8,\n",
    "                'scikit': 0.5,\n",
    "                'text_stats': 1.0,\n",
    "            },\n",
    "        )),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=params, \n",
    "                                       scoring='neg_log_loss',\n",
    "                                       n_iter=20, cv=3, n_jobs=2)\n",
    "\n",
    "    random_search.fit(train.text, train.author)\n",
    "    report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 0.62699142  0.62365921  0.62758621]<br>\n",
    "CPU times: user 349 ms, sys: 102 ms, total: 451 ms<br>\n",
    "Wall time: 3min 12s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-386d78a74f2d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-386d78a74f2d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    FAIL HERE FOR NOW\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "FAIL HERE FOR NOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Откри приблизително същите параметри, но не успя да стигне напълно до същия резултат.\n",
    "\n",
    "Ще използвам следния модел:\n",
    "\n",
    "TfIdf + MultinomialNB, без стеминг на текста.\n",
    "\n",
    "Mean validation score: -0.423 (std: 0.003)\n",
    "\n",
    "Ще ползвам и следните параметри:\n",
    "\n",
    "Parameters: {'features__stop_words': None, 'features__ngram_range': (1, 2), 'features__min_df': 2, 'features__max_df': 0.8, 'features__lowercase': False, 'features__analyzer': 'word', 'clf__alpha': 0.01}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Последна проверка на този модел за `LogLoss` и `Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(ngram_range=(1, 2), min_df=2,\n",
    "                                 max_df=0.8, lowercase=False)),\n",
    "    ('clf', MultinomialNB(alpha=0.01))\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Трениране на модел и събмит\n",
    "\n",
    "Първо да видим в какъв формат трябва да се подадат резултатите за тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"data/spooky-authors/sample_submission.zip\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = pipeline.fit(train.text, train.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(pipeline.predict_proba(test[:10].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = pipeline.predict_proba(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(pipeline.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "submit_file = pd.DataFrame(test_predictions, columns=['EAP', 'MWS', 'HPL'], index=test.index)\n",
    "submit_file.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "submit_file.to_csv(\"data/spooky-authors/submit_Tfidf_MNB_text.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Очакванията за събмита са да имаме скор някъде около 0.41 - 0.42.\n",
    "\n",
    "Може да е малко по-добър защото при крос-валидацията тренирахме на 13к и тествахме 6к.\n",
    "\n",
    "Сега трейн сета е целия: 19.5к"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![submit-result.png](attachment:submit-result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Да хакнем ранкинга в кагъл?\n",
    "\n",
    "print(test.text[:5].values)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "none",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
